---
title: "Picking a Bikometer"
output: github_document
---

# Goal

Determine which Bikeometers to include in my visualization. Bikeometers were excluded if they were missing data in the time range I was exploring. Bikeometers were also excluded if they were not in the Arlington region.

### Import the table

I'll start by importing the necessary packages and establishing a connection to the database.

```{r echo = FALSE, message = FALSE, warning= FALSE}
library(ggplot2)
library(dplyr)
library(odbc)

con <- dbConnect(odbc::odbc(), .connection_string = "Driver={MySQL ODBC 8.0 Unicode Driver};", 
                 server = "localhost", db = "counts", user = "root", password = rstudioapi::askForPassword("Database password"))
```

Next, I used the dplyr function tbl(), pass in the connection object that references the database 'counts' and the name of the table we want to look at 'counts_daily'. This will create a 'lazy table', importing only the first 10 rows. You can tell the entire table has not been imported because instead of listing the number of rows, it lists: 'Source: table<counts_daily> [?? x 5]'

```{r paged.print=TRUE}
# Imports to a lazy table
counts_daily <- tbl(con, 'counts_daily')
counts_daily
```

### Visualize the data

From what I've read, using 'for loops' are slow in R but I haven't been able to find another way to generate plots this easily.

So, I used a nested for loop to easily generate plots for each counter in the Arlington region. I've commented out all but one Bikeometer ID (28) to only generate plots for one Bikeometer for this website, but to test out the code, you can uncomment the rest of the vector to generate all the plots yourself.

```{r message=FALSE, paged.print=TRUE}

counts_daily <- tbl(con, 'counts_daily')

for (id in c(28)){#33,30,24,59,10,20,18,3,58,61,62,14,60,5,6,27,26,8,7,22,21,9,16,15,31,11,2,25,19)){
  for (year in c(2017,2018,2019,2020,2021)){
    start_date <- paste(year, '-03-12', sep = '', collapse = '-')
    end_date <- paste(year, '-05-15', sep = '', collapse = '-')
    counts_daily_filtered <- counts_daily %>% filter(date >= start_date & date <= end_date & bikeometer_id == id) %>% collect()

    p <- counts_daily_filtered %>% ggplot(aes(date, count)) +
    geom_point() +
    labs(
      title = 'Daily Bicycle Counts',
      subtitle = paste('Year = ', year, 'ID = ', id)) +
    xlab('Date') +
    ylab('Counts Daily') +
    ylim(0, 1200) +
    theme(
      plot.title = element_text(hjust = 0.5, vjust = 1),
      plot.subtitle = element_text(hjust = 0.5, vjust = -1, size = 10, face = 'italic')
      ) 
    print(p)
    #ggsave(filename = paste('ID ', id, ' Year ', year,' counts', '.jpg', sep = ''), path = '~/Github/Arlington_Bikeometer_Visualizations/Output', device = 'jpg', dpi = 'retina')
}}
```

Generating these plots returned an error at the 'Year = 2020' plot: 'Warning: Removed 1 rows containing missing values (geom_point)'.

### Fixing the Error

I wanted to look at the table to see what the data looked like exactly. So, I defined a SQL Select statement to filter by my desired date range and Bikeometer ID 28 (Rosslyn Bikeometer). The 'ORDER BY count desc' sorts the table by counts in descending order.

I ran the dbGetQuery() which lets me execute a defined SQL Select command, creating a filtered table, I assigned to my_filtered_table.

Using head(my_table), I was able to view the top 6 rows of my_table directly in R.

```{r}
sql_cmd <- "SELECT * FROM counts.counts_daily WHERE bikeometer_id = 28 AND date >= '2020-03-12' AND date <= '2020-05-15' ORDER BY count desc"
# creates a lazy table
my_filtered_table <- dbGetQuery(con, sql_cmd)
# displays the top 6 rows
head(my_filtered_table)
# When you are done, run: dbDisconnect(con)
```

Low and behold, the counts were too high for my chosen Y-Axis scale 'ylim(0,1000). So, I changed my y-axis limits.

I used the same function but adjusted the scale of the y-axis to 1600.

```{r message=FALSE, paged.print=TRUE}
counts_daily <- tbl(con, 'counts_daily')
for (id in c(28)){#2,3,7, 8, 10,11, 25, 26,28, 31, 39, 43, 47, 54, 56, 57)){
  for (year in c(2017,2018,2019,2020,2021)){
    start_date <- paste(year, '-03-12', sep = '', collapse = '-')
    end_date <- paste(year, '-05-15', sep = '', collapse = '-')
    counts_daily_filtered <- counts_daily %>% filter(date >= start_date & date <= end_date & bikeometer_id == id) %>% collect()
    
    p <- counts_daily_filtered %>% ggplot(aes(date, count)) +
    geom_point() +
    labs(
      title = 'Daily Bicycle Counts',
      subtitle = paste('Year = ', year, 'ID = ', id)) +
    xlab('Date') +
    ylab('Counts Daily') +
    ylim(0, 1600) +
    theme(
      plot.title = element_text(hjust = 0.5, vjust = 1),
      plot.subtitle = element_text(hjust = 0.5, vjust = -1, size = 10, face = 'italic')
      ) 
    print(p)
    #ggsave(filename = paste('ID ', id, ' Year ', year,' counts', '.svg', sep = ''), 
      #path = '~/Github/Arlington_Bikeometer_Visualizations/Output', device = 'svg', dpi = 'retina')
}}
```

Yes! No more errors. However, my joy was short-lived as I noticed big holes in 2020 and 2021 plots.

### Missing data or my mistake?

I can see that in 2020 and 2021 there is some missing data. In 2020, there is over a week of 0 counts and in 2021 some of the counts are just missing. When I manually queried the [Bike Arlingon web interface](%22http://counters.bikearlington.com/%22) for the missing dates, the count was reported as 0 but for some reason the data didn't get imported to my database as 0.

![](images/March%2019%202021%20Web%20Query.png "March 19, 2021 Web Query")

Investigating further, the data is just not on Bike Arlington's servers, which explains why sometimes the data is imported as 0 counts and sometimes the data isn't imported at all.

[![Making API call with URL](images/Web%20API%20URL%20call.jpg "Making API call with URL")](http://webservices.commuterpage.com/counters.cfc?wsdl&method=GetCountInDateRange&counterid=28&startDate=03/19/2021&endDate=3/19/2021&interval=d)

If I were to recreate my database of counts, I would include a clause 'if there is no data to import for a time-point, count = 0'. The Bike Arlington people probably have a similar clause, which probably prevents the web interface from breaking when a vaild query is made but no data is in the serve.

### Chosen Bikeometers

After looking through each plot, I found these Bikeometers without missing data: 14,15,16,18,22,31,39.

#### Note: Filling in the missing data

The MnDOT released their data quality management procedures in [Minnesota's Walking and Bicycling Data Collection Report Update](https://www.dot.state.mn.us/bike-ped-counting/reports/2018-2019%20MinnesotaPedBikeCountReport.pdf). Here, they list how they remove outlier, review suspicious data points, create a linear regression model, and use said regression model to **estimate daily traffic for missing days**. In the future, I'd like to preform a similar analysis to fill in the missing data.

################ end
