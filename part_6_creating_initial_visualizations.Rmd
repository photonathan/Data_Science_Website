---
title: "Visualizing Arlington Bikometers"
subtitle: "Part 5: Creating the Initial Visualizations"
output:
  html_document: 
    toc: yes
    toc_depth: 2
    toc_float: yes
    highlight: zenburn
    code_download: true
    df_print: paged
    code_folding: hide
    includes:
      in_header: header.html
---

# Goal

Create a post with similar parameters to the [Minnesota DOT's](https://storymaps.arcgis.com/stories/70a3a57003b541ed8e911cd11103dc6a) *Covid-19 & Historic Total Traffic Count* graph.

# Connect to MySQL Database

```{r echo = FALSE, message = FALSE, warning= FALSE, include=TRUE}
library(ggplot2)
library(dplyr)
library(odbc)
library(reshape2)
library(tidyr)

con <- dbConnect(odbc::odbc(), dsn = "Bike_MySQL")
```

# Load the table into R

```{r}
counts_daily <- tbl(con, 'counts_daily')
head(counts_daily)
```

# Combining 'In' and 'Out' Values

In Part 5, we used the below *dplyr* code to combine the 'I' and 'O' values.


```{r}
counts_daily_total <- counts_daily %>% 
  group_by(date, bikeometer_id) %>% 
  summarize(count = sum(count), is_weekend = is_weekend, 
            month = month, day = day, year = year, month_day = month_day) %>% 
  collect()
counts_daily_total
```

```{r}
class(counts_daily_total$month_day)
```

I'm going to manipulate the counts_daily_total *tibble* using the *mutate* function.

I realized that I should have used a hyphen instead of an underscore for 'month-day' rows so first I need to do some character replacement. I'll use the gsub() function to replace the underscore with a hyphen.   

Then, we will add an arbitrary year to the end of month_day to make it easier to convert to a *date* class and subsequently graph.

```{r}
counts_daily_total <- counts_daily_total %>% mutate(month_day = gsub("[_]", "-", month_day))

counts_daily_total <- counts_daily_total %>% mutate(month_day=paste(month_day, '-2020', sep = ''))
counts_daily_total

```

### Note to self
Originally, class(counts_daily_total$year,month,day == 'S3 value Bigint' which doesn't play nicely with dplyr. Be sure to convert number columns into *int* before applying filters. Also, for when mutating a column, don't assign the mutate like this:

```{r eval=FALSE}
# Don't use this
counts_daily_total$month_day <- counts_daily_total %>% mutate(month_day = gsub("[_]", "-", month_day))

# Use this!
counts_daily_total <- counts_daily_total %>% mutate(month_day = gsub("[_]", "-", month_day))

```


# Filtering for Date Range and Bikeometer ID

In a previous post, I chose a time-frame and which Bikeometers were best to plot. 

```{r}
counts_daily_filtered <- counts_daily_total %>% 
  filter(date >= '2017-03-12' & date <= '2017-05-15' & bikeometer_id %in% c(14,15,16,18,22,31,39)| 
         date >= '2018-03-12' & date <= '2018-05-15' & bikeometer_id %in% c(14,15,16,18,22,31,39)|
         date >= '2019-03-12' & date <= '2019-05-15' & bikeometer_id %in% c(14,15,16,18,22,31,39)| 
         date >= '2020-03-12' & date <= '2020-05-15' & bikeometer_id %in% c(14,15,16,18,22,31,39))
  
counts_daily_filtered
```

Let's convert month_day to a *date* class so it is easier to manipulate.


```{r}
class(counts_daily_filtered$month_day)
```

May need to convert month_day to 04-06 format instead of 4_6



```{r}
counts_daily_filtered$month_day <- mutate(counts_daily_filtered, month_day = gsub("[_]", "-", month_day))
class(counts_daily_filtered$month_day[1])

counts_daily_filtered %>% mutate(month_day = gsub("[_]", "-", month_day))

counts_daily_filtered %>% mutate(month_day = str_replace(month_day, "_", "-"))

m_d <- '4_6' 
m_d
m_d <- str_replace(m_d, "_", "-")
m_d  
counts_daily_filtered$month_day <- strptime(counts_daily_filtered$month_day, '%m-%d-%Y')
class(counts_daily_filtered$month_day[1])

counts_daily_filtered$month_day <- as.Date(counts_daily_filtered$month_day)
class(counts_daily_filtered$month_day[1])
```
```{r}
counts_daily_filtered

```

```{r}
m_d <- '4_6' 
m_d
m_d <- gsub("[_]", "-", m_d)
m_d
m_d <- strptime(m_d, '%m-%d')
m_d
```

```

counts_daily_filtered$month_day
```

```{r}
counts_daily_filtered %>% summarise(
  average_count = mean(count)),
  group_by(month_day, bikeometer_id)
```
```{r}
counts_daily_filtered %>% group_by(month_day) %>% summarise(avg_counts = mean(count))
```


# Creating the 2017-2019 Daily Average column

```{sql connection=con, evaluate=FALSE }
CREATE OR REPLACE VIEW counts_daily_average_2017_to_2019
AS select 
cd.month_day as month_day,
AVG(cd.count) as average
FROM vw_filtered_counts_daily_total_2017_to_2019 cd
LEFT JOIN vw_filtered_counts_daily_total_2017_to_2019 a ON cd.month_day = a.month_day
GROUP BY cd.month_day;
```

```{r cache=TRUE}
counts_daily_average_2017_to_2019 <- tbl(con, 'counts_daily_average_2017_to_2019')
counts_daily_average_2017_to_2019
```

Can use this as a select statement to view these two tables, minus the first line (CREATE TABLE the_best_table AS).

```{sql connection=con, evaluate=FALSE}
CREATE TABLE the_best_table AS
SELECT a.month_day, a.average_2017_to_2019, average_2020
FROM counts_daily_average_2017_to_2019 A 
INNER JOIN counts_daily_average_2020 B ON B.month_day = A.month_day
```

```{r message=FALSE}
df <- tbl(con, 'the_best_table')
# These Bikeometers are all located in the Arlington region
```

In order for this table to be easily read by R, we need to covert it from a wide table to a long table. [This]('https://mgimond.github.io/ES218/Week03b.html') is the resource I used to understand how to do the conversion.

```{r}
df.long <- pivot_longer(df, cols=2:3, names_to='year', values_to='counts')
```

Here I added the year to the end of the all the month_day values then convert that to a date class so R has an easy time graphing it.

```{r}
df.long <- mutate(df.long, month_day=paste(month_day, '-2020', sep = ''))
df.long <- collect(df.long)
```

```{r}
df.long.filtered <- df.long %>% filter(month_day >= '03-12-2020' & month_day <= '05-15-2020') %>% collect()
df.long.filtered
```

Finally I convert the month_day values from a 'character class' to a time class. Be sure to lowercase the 'm' and 'd' in '%m-%d-%Y'.

```{r}
df.long.filtered$month_day <- strptime(df.long.filtered$month_day, '%m-%d-%Y')
class(df.long.filtered$month_day[1])
df.long.filtered$month_day <- as.Date(df.long.filtered$month_day)
class(df.long.filtered$month_day[1])
```
```{r}
df.long.filtered$counts <- as.integer(df.long.filtered$counts)
```

```{r}
df.long.filtered
```
```{r}
line <- ggplot(df.long.filtered, (aes(x=month_day, y=counts, fill=year, group=year))) + geom_line()
line
```
```{r}
ggplotly(line)
```
```{r}
line + geom_area()
```


```{r}
p <- ggplot(df.long.filtered, (aes(x=month_day, y=counts))) + geom_area((aes(colour=year, fill=year)))
p
```
```{r}
ggplotly(p)
```

```{r}
library(plotly)
```




```{r}
ggplot(diamonds, aes(price, fill = cut)) +
     geom_density(bins = 50, stat = "bin", alpha = 0.3) 
```


```{r}
time <- as.numeric(rep(seq(1,7),each=7))  # x Axis
value <- runif(49, 10, 100)               # y Axis
group <- rep(LETTERS[1:7],times=7)        # group, one shape per group
data <- data.frame(time, value, group)

# stacked area chart
test <- ggplot(data, aes(x=time, y=value, fill=group)) + 
    geom_area()
test
```

```{r}
ggplotly(test)
```

```{r}
data
```


It looks like there definitely was an increase but it doesn't look as nice as the MnDOT plot. Let's investigate this a little.

# Bikeometer Locations

I'll map the locations of the Bikeometers to see where exactly they are in Arlington. To accomplish this, I found [this video](https://www.youtube.com/watch?v=2k8O-Y_uiRU&t=3s) by Professor Lisa Lendway very helpful along with [her website](https://mapping-in-r.netlify.app/).

![](images/Arlington%20Open%20Street%20Map.png "Arlington Open Street Map bbox")

On the left are the numbers we need to enter into the bbox variable below in order to get the graph from [Stamen Maps](http://maps.stamen.com/). I've chosen 'terrain' as my map type and the 'zoom' will be 13, which is in the openstreetmap url just after the text 'map='.

```{r message=FALSE}
library(ggmap)
library(ggthemes)
# Get the map information
arlington <- get_stamenmap(
    bbox = c(left = -77.2377, bottom = 38.8075, right = -76.9744, top = 38.9080), 
    maptype = "terrain",
    zoom = 12)
```

Next we will import the Bikeometer data from my database that contains the longitude and latitudes needed to plot the Bikeometers.

```{r}
sql_cmd <- "SELECT * FROM counts.bikeometer_details WHERE bikeometer_id in (14,15,16,18,22,31,39)"
# creates a lazy table
bikeometer_table <- dbGetQuery(con, sql_cmd)
bikeometer_table
```

One Bikeometer stands out as not even being in Alrington... how did that get in there? Let's plot it anyway to see how close it is to Arlington. Realistically, I frequently bike into Alexandria on the weekends but I'll probably end up excluding it none the less.

```{r}
# Convert latitude and longitude to integers
bikeometer_table$longitude <- as.numeric(bikeometer_table$longitude)
bikeometer_table$latitude <- as.numeric(bikeometer_table$latitude)

# Plot the points on the map
ggmap(arlington) + # creates the map "background"
  geom_point(data = bikeometer_table, 
             aes(x = longitude, y = latitude, color = region), 
             alpha = 0.5, 
             size = 3) +
             theme_map()
```

From my experience, the most popular bike trail in Arlington will be on the Arlington Loop. I want to get a sense if these Bikeometers are on the Arlington Loop, and if not, choose Bikeometers that are on the loop. My hypothesis is that bike trails that weren't popular before the pandemic won't see much change after the pandemic. I generally either ride the Arlington Loop or the W&OD Trails as they are the most bike-friendly. A trail that is less bike-friendly before the pandemic won't become that much more bike-friendly during a pandemic, even if there is a reduction of traffic in the city.

I'll use the GPS coordinates from my Garmin GPS watch to create a layer for my plot that shows the Arlington Loop trail. I downloaded the gpx file from the Garmin Connect website.

![](images/GPX%20file%20from%20Garmin%20Connect%20Website.jpg "Garmin Connect GPX")

I used the websites [GPXStudio](https://gpxstudio.github.io/) and [MyGeodata Converter](https://mygeodata.cloud/converter/gpx-to-csv) to remove unnecessary data points and convert from GPX to CSV respectively.

I read in the CSV which I'll use to plot the Arlington Loop.

```{r}
arlington_loop_table <- read.csv('~/Github/Arlington_Bikeometer_Visualizations/Data/arlington_loop.csv')
arlington_loop_table
```

I passed the 'arlington' map object to ggmap to set the background image to Arlington then plotted the Arlington Loop using geom_point. I used the 'longitude' column as the x-axis, 'latitude' column as the y-axis, 'alpha' is the transparency of the points (0 to 1) and 'size' is the size of each point. I used 'theme_map' without 'x' and 'y' axes.

```{r}
ggmap(arlington) + # creates the map "background"
  geom_point(data = arlington_loop_table, 
             aes(x = longitude, y = latitude), 
             alpha = 0.5, 
             size = .5) +
             theme_map()
```

Next, I'll create an Arlington Loop layer so I can overlay it on top of the Bikeometer location map. I found two options to create this layer: geom_polygon or geom_path. The biggest diffrence I see is that you can specify a fill for geom_polygon, but considering I don't want to fill the layer in, I'll use geom_path.

```{r}
ggmap(arlington) + geom_polygon(aes(x = longitude, y = latitude),
                             data = arlington_loop_table, fill = 'blue', alpha = 0.1, size = 1, color = "red")
```

```{r}
ggmap(arlington) + geom_path(data = arlington_loop_table, aes(x = longitude, y = latitude), size = 1, color = 'red') + theme_map()

```

If I wanted the path to change color according to elevation, I could use the below \<color = ele\> argument. This will generate a legend on the map. By adding the \<theme(legend.background = element_blank())\> code, you remove the background from the legend. However I won't be using this code.

```{r}
ggmap(arlington) + geom_path(data = arlington_loop_table, aes(x = longitude, y = latitude, color = ele), size = 1) + theme_map() + theme(legend.background = element_blank())
```

I'll assign the geom_path to the arlington_loop_layer variable to be plotted on top of the plot with the location of the Bikeometes.

```{r}
arlington_loop_layer <- geom_path(data = arlington_loop_table, aes(x = longitude, y = latitude), size = 1, color = 'red')
```

```{r}
ggmap(arlington) + # creates the map "background"
  geom_point(data = bikeometer_table, 
             aes(x = longitude, y = latitude, color = region), 
             alpha = 0.5, 
             size = 3) +
              arlington_loop_layer +
             theme_map()
```

It looks like 1 or 2 Bikeometers are on the trail, I'm not sure of the accuracy of the GPS data from any source.

Let's see what Bikeometers are actually on the Arlington Loop. I can use that data to pick some popular trails to visualize.

```{r}
sql_cmd <- "SELECT * FROM counts.bikeometer_details"
# creates a lazy table
all_bikeometer_table <- dbGetQuery(con, sql_cmd)
all_bikeometer_table$longitude <- as.numeric(all_bikeometer_table$longitude)
all_bikeometer_table$latitude <- as.numeric(all_bikeometer_table$latitude)
all_bikeometer_table
```

To figure out labeling, I used [this site](https://rafalab.github.io/dsbook/ggplot2.html).

```{r}
ggmap(arlington) + # creates the map "background"
  geom_point(data = bikeometer_table, 
             aes(x = longitude, y = latitude, color = region), 
             alpha = 0.5, 
             size = 10) +
              arlington_loop_layer +
  geom_text(data = bikeometer_table, nudge_x = 0.01, aes(x = longitude, y = latitude, color = region, 
                                         label = bikeometer_id, inherit.aes= FALSE))+
  theme_map()
```



For some reason, bikeometer_id 6 isn't in my database. I'll quickly covert my list of Bikeometers into integers so I can use the sorted() function in python to order them.

```{r include=FALSE, cache=TRUE}
library(reticulate)
```

```{python}
bikeometer_list = ['33','30','43','24','59','56','47','48','10','20',
                           '35','57','18','3','58','61','62','38','44','14',
                           '60','5','6','42','37','27','26','8','7','51','52',
                           '45','22','21','36','34','41','9','39','16','15',
                           '54','55','31','28','11','2','25','19']

# Convert to integers
bikeometer_list = [int(i) for i in bikeometer_list]
sorted_bikeometer_list = sorted(bikeometer_list)
sorted_bikeometer_list
```

With them ordered, I'll check to see which Bikeometers are in my database.

It looks like Bikeometers 6 and 52 are not in my database. When I request data from them for a few different time ranges, it looks like there is no data for either of them, which explains why they aren't in my database. One mystery solved!
